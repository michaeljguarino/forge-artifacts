apiVersion: apps/v1
kind: Deployment
metadata:
  name: activator
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: activator
    app.kubernetes.io/version: "0.26.0"
    app.kubernetes.io/part-of: knative-serving
spec:
  selector:
    matchLabels:
      app: activator
      role: activator
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
      labels:
        app: activator
        role: activator
        serving.knative.dev/release: "v0.26.0"
        app.kubernetes.io/name: activator
        app.kubernetes.io/part-of: knative-serving
        app.kubernetes.io/version: "0.26.0"
    spec:
      serviceAccountName: controller
      containers:
        - name: activator
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.activator.registry }}/{{ .Values.images.activator.repository }}:{{ .Values.images.activator.tag }}
          # The numbers are based on performance test results from
          # https://github.com/knative/serving/issues/1625#issuecomment-511930023
          resources:
            requests:
              cpu: 300m
              memory: 60Mi
            limits:
              cpu: 1000m
              memory: 600Mi
          env:
            # Run Activator with GC collection when newly generated memory is 500%.
            - name: GOGC
              value: "500"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/internal/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
            - name: http1
              containerPort: 8012
            - name: h2c
              containerPort: 8013
          readinessProbe:
            httpGet:
              port: 8012
              httpHeaders:
                - name: k-kubelet-probe
                  value: "activator"
            failureThreshold: 12
          livenessProbe:
            httpGet:
              port: 8012
              httpHeaders:
                - name: k-kubelet-probe
                  value: "activator"
            failureThreshold: 12
            initialDelaySeconds: 15
      # The activator (often) sits on the dataplane, and may proxy long (e.g.
      # streaming, websockets) requests.  We give a long grace period for the
      # activator to "lame duck" and drain outstanding requests before we
      # forcibly terminate the pod (and outstanding connections).  This value
      # should be at least as large as the upper bound on the Revision's
      # timeoutSeconds property to avoid servicing events disrupting
      # connections.
      terminationGracePeriodSeconds: 600
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: autoscaler
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: autoscaler
    app.kubernetes.io/part-of: knative-serving
    app.kubernetes.io/version: "0.26.0"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: autoscaler
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
      labels:
        app: autoscaler
        serving.knative.dev/release: "v0.26.0"
        app.kubernetes.io/name: autoscaler
        app.kubernetes.io/part-of: knative-serving
        app.kubernetes.io/version: "0.26.0"
    spec:
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: autoscaler
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: controller
      containers:
        - name: autoscaler
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.autoscaler.registry }}/{{ .Values.images.autoscaler.repository }}:{{ .Values.images.autoscaler.tag }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 1000m
              memory: 1000Mi
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
            - name: websocket
              containerPort: 8080
          readinessProbe:
            httpGet:
              port: 8080
              httpHeaders:
                - name: k-kubelet-probe
                  value: "autoscaler"
          livenessProbe:
            httpGet:
              port: 8080
              httpHeaders:
                - name: k-kubelet-probe
                  value: "autoscaler"
            failureThreshold: 6
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: controller
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: controller
    app.kubernetes.io/version: "0.26.0"
    app.kubernetes.io/part-of: knative-serving
spec:
  selector:
    matchLabels:
      app: controller
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      labels:
        app: controller
        serving.knative.dev/release: "v0.26.0"
        app.kubernetes.io/name: controller
        app.kubernetes.io/version: "0.26.0"
        app.kubernetes.io/part-of: knative-serving
    spec:
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: controller
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: controller
      containers:
        - name: controller
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.controller.registry }}/{{ .Values.images.controller.repository }}:{{ .Values.images.controller.tag }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 1000m
              memory: 1000Mi
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/internal/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: domain-mapping
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: domain-mapping
    app.kubernetes.io/version: "0.26.0"
    app.kubernetes.io/part-of: knative-serving
spec:
  selector:
    matchLabels:
      app: domain-mapping
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      labels:
        app: domain-mapping
        serving.knative.dev/release: "v0.26.0"
        app.kubernetes.io/name: domain-mapping
        app.kubernetes.io/part-of: knative-serving
        app.kubernetes.io/version: "0.26.0"
    spec:
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: domain-mapping
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: controller
      containers:
        - name: domain-mapping
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.domainMapping.registry }}/{{ .Values.images.domainMapping.repository }}:{{ .Values.images.domainMapping.tag }}
          resources:
            requests:
              cpu: 30m
              memory: 40Mi
            limits:
              cpu: 300m
              memory: 400Mi
          env:
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: domainmapping-webhook
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: domainmapping-webhook
    app.kubernetes.io/version: "0.26.0"
    app.kubernetes.io/part-of: knative-serving
spec:
  selector:
    matchLabels:
      app: domainmapping-webhook
      role: domainmapping-webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
      labels:
        app: domainmapping-webhook
        app.kubernetes.io/name: domainmapping-webhook
        app.kubernetes.io/part-of: knative-serving
        app.kubernetes.io/version: "0.26.0"
        role: domainmapping-webhook
        serving.knative.dev/release: "v0.26.0"
    spec:
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: domainmapping-webhook
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: controller
      containers:
        - name: domainmapping-webhook
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.domainMappingWebhook.registry }}/{{ .Values.images.domainMappingWebhook.repository }}:{{ .Values.images.domainMappingWebhook.tag }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 500m
              memory: 500Mi
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            - name: WEBHOOK_PORT
              value: "8443"
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
            - name: https-webhook
              containerPort: 8443
          readinessProbe:
            periodSeconds: 1
            httpGet:
              scheme: HTTPS
              port: 8443
              httpHeaders:
                - name: k-kubelet-probe
                  value: "webhook"
          livenessProbe:
            periodSeconds: 1
            httpGet:
              scheme: HTTPS
              port: 8443
              httpHeaders:
                - name: k-kubelet-probe
                  value: "webhook"
            failureThreshold: 6
            initialDelaySeconds: 20
      # Our webhook should gracefully terminate by lame ducking first, set this to a sufficiently
      # high value that we respect whatever value it has configured for the lame duck grace period.
      terminationGracePeriodSeconds: 300
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: net-istio-controller
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    networking.knative.dev/ingress-provider: istio
spec:
  selector:
    matchLabels:
      app: net-istio-controller
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        # This must be outside of the mesh to probe the gateways.
        # NOTE: this is allowed here and not elsewhere because
        # this is the Istio controller, and so it may be Istio-aware.
        sidecar.istio.io/inject: "false"
      labels:
        app: net-istio-controller
        serving.knative.dev/release: "v0.26.0"
    spec:
      serviceAccountName: controller
      containers:
        - name: controller
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.netIstioController.registry }}/{{ .Values.images.netIstioController.repository }}:{{ .Values.images.netIstioController.tag }}
          resources:
            requests:
              cpu: 30m
              memory: 40Mi
            limits:
              cpu: 300m
              memory: 400Mi
          env:
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/net-istio
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: net-istio-webhook
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    networking.knative.dev/ingress-provider: istio
spec:
  selector:
    matchLabels:
      app: net-istio-webhook
      role: net-istio-webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
      labels:
        app: net-istio-webhook
        role: net-istio-webhook
        serving.knative.dev/release: "v0.26.0"
    spec:
      serviceAccountName: controller
      containers:
        - name: webhook
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.netIstioWebhook.registry }}/{{ .Values.images.netIstioWebhook.repository }}:{{ .Values.images.netIstioWebhook.tag }}
          resources:
            requests:
              cpu: 20m
              memory: 20Mi
            limits:
              cpu: 200m
              memory: 200Mi
          env:
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/net-istio
            - name: WEBHOOK_NAME
              value: net-istio-webhook
          securityContext:
            allowPrivilegeEscalation: false
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
            - name: https-webhook
              containerPort: 8443
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webhook
  namespace: {{ .Release.Namespace }}
  labels:
    serving.knative.dev/release: "v0.26.0"
    app.kubernetes.io/name: webhook
    app.kubernetes.io/version: "0.26.0"
    app.kubernetes.io/part-of: knative-serving
spec:
  selector:
    matchLabels:
      app: webhook
      role: webhook
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
      labels:
        app: webhook
        role: webhook
        serving.knative.dev/release: "v0.26.0"
        app.kubernetes.io/name: webhook
        app.kubernetes.io/version: "0.26.0"
        app.kubernetes.io/part-of: knative-serving
    spec:
      # To avoid node becoming SPOF, spread our replicas to different nodes.
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: webhook
                topologyKey: kubernetes.io/hostname
              weight: 100
      serviceAccountName: controller
      containers:
        - name: webhook
          # This is the Go import path for the binary that is containerized
          # and substituted here.
          image: {{ .Values.images.webhook.registry }}/{{ .Values.images.webhook.repository }}:{{ .Values.images.webhook.tag }}
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
            limits:
              cpu: 500m
              memory: 500Mi
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: SYSTEM_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONFIG_LOGGING_NAME
              value: config-logging
            - name: CONFIG_OBSERVABILITY_NAME
              value: config-observability
            - name: WEBHOOK_NAME
              value: webhook
            - name: WEBHOOK_PORT
              value: "8443"
            # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
            - name: METRICS_DOMAIN
              value: knative.dev/internal/serving
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            capabilities:
              drop:
                - all
          ports:
            - name: metrics
              containerPort: 9090
            - name: profiling
              containerPort: 8008
            - name: https-webhook
              containerPort: 8443
          readinessProbe:
            periodSeconds: 1
            httpGet:
              scheme: HTTPS
              port: 8443
              httpHeaders:
                - name: k-kubelet-probe
                  value: "webhook"
          livenessProbe:
            periodSeconds: 1
            httpGet:
              scheme: HTTPS
              port: 8443
              httpHeaders:
                - name: k-kubelet-probe
                  value: "webhook"
            failureThreshold: 6
            initialDelaySeconds: 20
      # Our webhook should gracefully terminate by lame ducking first, set this to a sufficiently
      # high value that we respect whatever value it has configured for the lame duck grace period.
      terminationGracePeriodSeconds: 300
